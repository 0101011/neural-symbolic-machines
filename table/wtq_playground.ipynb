{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import nsm\n",
    "from nsm import data_utils\n",
    "from nsm import env_factory\n",
    "from nsm import graph_factory\n",
    "from nsm import model_factory\n",
    "from nsm import agent_factory\n",
    "from nsm import executor_factory\n",
    "from nsm import computer_factory\n",
    "from nsm import word_embeddings\n",
    "\n",
    "import experiment as exp\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS  \n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the path to your data/wikitable folder. \n",
    "# By default it is in ~/projects/data/wikitable. \n",
    "data_dir= os.path.expanduser('~/projects/data/wikitable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.eval_only = True\n",
    "FLAGS.eval_use_gpu = False\n",
    "FLAGS.eval_gpu_id = 0\n",
    "FLAGS.eval_file = os.path.join(data_dir, 'processed_input/preprocess_14/data_split_1/dev_split.jsonl')\n",
    "unittest_file = os.path.join(data_dir, 'processed_input/preprocess_14/data_split_1/train_split_shard_90-0.jsonl')\n",
    "train_file = os.path.join(data_dir, 'processed_input/preprocess_14/train_examples.jsonl')\n",
    "\n",
    "# Fill in the output folder and experiment name you want to load.\n",
    "# By default, load the pretrained model in the repo. \n",
    "FLAGS.output_dir = os.path.expanduser('~/projects/neural-symbolic-machines/table/wtq/')\n",
    "FLAGS.experiment_to_eval = 'pretrained_model'\n",
    "experiment_config = exp.create_experiment_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:2831 examples in dataset.\n",
      "INFO:tensorflow:2108 tables.\n",
      "INFO:tensorflow:2045 unique tokens in encoder vocab\n",
      "INFO:tensorflow:2831 examples in the dataset\n",
      "INFO:tensorflow:creating environment #0\n",
      "INFO:tensorflow:creating environment #100\n",
      "INFO:tensorflow:creating environment #200\n",
      "INFO:tensorflow:creating environment #300\n",
      "INFO:tensorflow:creating environment #400\n",
      "INFO:tensorflow:creating environment #500\n",
      "INFO:tensorflow:creating environment #600\n",
      "INFO:tensorflow:creating environment #700\n",
      "INFO:tensorflow:creating environment #800\n",
      "INFO:tensorflow:creating environment #900\n",
      "INFO:tensorflow:creating environment #1000\n",
      "INFO:tensorflow:creating environment #1100\n",
      "INFO:tensorflow:creating environment #1200\n",
      "INFO:tensorflow:creating environment #1300\n",
      "INFO:tensorflow:creating environment #1400\n",
      "INFO:tensorflow:creating environment #1500\n",
      "INFO:tensorflow:creating environment #1600\n",
      "INFO:tensorflow:creating environment #1700\n",
      "INFO:tensorflow:creating environment #1800\n",
      "INFO:tensorflow:creating environment #1900\n",
      "INFO:tensorflow:creating environment #2000\n",
      "INFO:tensorflow:creating environment #2100\n",
      "INFO:tensorflow:creating environment #2200\n",
      "INFO:tensorflow:creating environment #2300\n",
      "INFO:tensorflow:creating environment #2400\n",
      "INFO:tensorflow:creating environment #2500\n",
      "INFO:tensorflow:creating environment #2600\n",
      "INFO:tensorflow:creating environment #2700\n",
      "INFO:tensorflow:creating environment #2800\n",
      "INFO:tensorflow:2831 environments in total\n",
      "INFO:tensorflow:Start creating and initializing graph\n",
      "INFO:tensorflow:trainable parameters:\n",
      "INFO:tensorflow:memory_seq2seq_graph/ConstantInput/dense/kernel:0: 60000\n",
      "INFO:tensorflow:memory_seq2seq_graph/ConstantInput/dense/bias:0: 200\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/embeddings:0: 800\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/dense/kernel:0: 60000\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/dense/bias:0: 200\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0: 320800\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0: 800\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0: 320000\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0: 800\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/bidirectional_rnn/bw/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0: 320800\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/bidirectional_rnn/bw/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0: 800\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/bidirectional_rnn/bw/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0: 320000\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/bidirectional_rnn/bw/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0: 800\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/dense_1/kernel:0: 80000\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Encoder/dense_1/bias:0: 200\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/ConstantEncoder/builtin_de_embeddings:0: 6200\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0: 320000\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0: 800\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0: 320000\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0: 800\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/attention/dense/kernel:0: 40000\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/attention/dense/bias:0: 200\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/attention/dense_1/kernel:0: 40000\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/attention/dense_1/bias:0: 200\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/attention/dense_2/kernel:0: 40000\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/attention/dense_2/bias:0: 200\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/attention/attn_v:0: 200\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/attn_output_projection/weights:0: 80000\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/rnn/attention_cell_wrapper/attn_output_projection/biases:0: 200\n",
      "INFO:tensorflow:memory_seq2seq_graph/MemorySeq2seq/Decoder/de_output_feature_weights:0: 1\n",
      "INFO:tensorflow:total number of trainable parameters 2335001\n",
      "INFO:tensorflow:adam beta1: 0.9\n",
      "INFO:tensorflow:number of gpu used 1\n",
      "INFO:tensorflow:Restoring parameters from /Users/crazydonkey/projects/data/wikitable/output/pretrained_model/best_model/model-19840\n",
      "INFO:tensorflow:4.84319901466 sec used to create and initialize graph\n",
      "INFO:tensorflow:Start creating model and agent\n",
      "INFO:tensorflow:0.0185940265656 sec used to create model and agent\n"
     ]
    }
   ],
   "source": [
    "# Load the agent and the environments in the dev set. \n",
    "# This usually takes 15-30 sec. \n",
    "# If you want to see the training environments, use train_file instead (takes about 75-150 sec). \n",
    "fns = [FLAGS.eval_file]\n",
    "agent, envs = exp.init_experiment(fns, FLAGS.eval_use_gpu, gpu_id=str(FLAGS.eval_gpu_id))\n",
    "for env in envs:\n",
    "    env.punish_extra_work = False\n",
    "env_dict = dict([(env.name, env) for env in envs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on the first 10 environments and show generated programs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:==================================================\n",
      "INFO:tensorflow:eval, batch 0: 10 envs\n",
      "INFO:tensorflow:50 samples in beam, batch 0.\n",
      "INFO:tensorflow:1.7073469162 sec used in evaluator batch 0.\n",
      "INFO:tensorflow:avg return adjusted from 0.6 to 0.6 based on true n\n",
      "INFO:tensorflow:10 samples in non-empty beam.\n",
      "INFO:tensorflow:true n is 10\n",
      "INFO:tensorflow:10 questions in dev set.\n",
      "INFO:tensorflow:0.6 dev avg return.\n",
      "INFO:tensorflow:dev: avg return: 0.6, avg length: 14.1.\n",
      "Accuracy on the selected 10 environments are 0.6\n",
      "Show the generated programs:\n",
      "\n",
      "env nt-34\n",
      "question: who was the top ranked competitor in this race?\n",
      "answer: [u'Iryna Shpylova', u'Iryna Shpylova']\n",
      "program: ( first all_rows ) ( hop v7 r.cyclist-string ) <END>\n",
      "prediction: [u'iryna shpylova']\n",
      "return: 1.0\n",
      "prob is 1.0\n",
      "\n",
      "env nt-40\n",
      "question: what was the number of silver medals won by ukraine?\n",
      "answer: [u'2', u'2.0']\n",
      "program: ( filter_str_contain_any all_rows [u'ukraine'] r.nation-string ) ( hop v12 r.silver-number ) <END>\n",
      "prediction: [2.0]\n",
      "return: 1.0\n",
      "prob is 1.0\n",
      "\n",
      "env nt-15\n",
      "question: what was the venue when he placed first?\n",
      "answer: [u'New Delhi, India', u'New Delhi, India']\n",
      "program: ( argmin all_rows r.position-number ) ( first all_rows ) ( diff v10 v9 r.year-number ) <END>\n",
      "prediction: [0.0]\n",
      "return: 0.0\n",
      "prob is 1.0\n",
      "\n",
      "env nt-14\n",
      "question: which athlete was from south korea after the year 2010?\n",
      "answer: [u'Kim Yu-na', u'Kim Yu-na']\n",
      "program: ( filter_str_contain_any all_rows [u'2010'] r.olympics-string ) ( hop v16 r.athlete-string ) <END>\n",
      "prediction: [u'aliona savchenko / robin szolkowy', u'shen xue / zhao hongbo', u'meryl davis / charlie white', u'kim yu-na', u'tessa virtue / scott moir']\n",
      "return: 0.0\n",
      "prob is 1.0\n",
      "\n",
      "env nt-3\n",
      "question: how many more passengers flew to los angeles than to saskatoon from manzanillo airport in 2013?\n",
      "answer: [u'12,467', u'12467.0']\n",
      "program: ( filter_str_contain_any all_rows [u'saskatoon'] r.city-string ) ( filter_str_contain_any all_rows [u'los angeles'] r.city-string ) ( diff v11 v10 r.passengers-number ) <END>\n",
      "prediction: [12467.0]\n",
      "return: 1.0\n",
      "prob is 1.0\n",
      "\n",
      "env nt-2\n",
      "question: which team won previous to crettyard?\n",
      "answer: [u'Wolfe Tones', u'Wolfe Tones']\n",
      "program: ( filter_str_contain_any all_rows [u'crettyard'] r.team-string ) ( previous v8 ) ( hop v9 r.team-string ) <END>\n",
      "prediction: [u'confey']\n",
      "return: 0.0\n",
      "prob is 1.0\n",
      "\n",
      "env nt-24\n",
      "question: who ranked right after turkey?\n",
      "answer: [u'Sweden', u'Sweden']\n",
      "program: ( filter_str_contain_any all_rows [u'turkey'] r.nation-string ) ( next v12 ) ( hop v13 r.nation-string ) <END>\n",
      "prediction: [u'sweden']\n",
      "return: 1.0\n",
      "prob is 1.0\n",
      "\n",
      "env nt-29\n",
      "question: what is the total population in dzhebariki-khaya?\n",
      "answer: [u'1694', u'1694.0']\n",
      "program: ( filter_str_contain_any all_rows [u'dzhebariki-khaya'] r.urban_settlements-string ) ( hop v13 r.population-number ) <END>\n",
      "prediction: [1694.0]\n",
      "return: 1.0\n",
      "prob is 1.0\n",
      "\n",
      "env nt-9\n",
      "question: which players played the same position as ardo kreek?\n",
      "answer: [u'Siim Ennemuist|Andri Aganits', u'Siim Ennemuist|Andri Aganits']\n",
      "program: ( filter_str_contain_any all_rows [u'ardo kreek'] r.player-string ) ( same v14 r.position-string ) ( hop v15 r.player-string ) <END>\n",
      "prediction: [u'andri aganits', u'siim ennemuist']\n",
      "return: 1.0\n",
      "prob is 1.0\n",
      "\n",
      "env nt-8\n",
      "question: after winning on four credits with a full house, what is your payout?\n",
      "answer: [u'32', u'32.0']\n",
      "program: ( argmax all_rows r.5_credits-number ) ( hop v19 r.1_credit-string ) <END>\n",
      "prediction: [u'250']\n",
      "return: 0.0\n",
      "prob is 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_envs = envs[:10]\n",
    "dev_avg_return, dev_samples, dev_samples_in_beam = exp.beam_search_eval(agent, eval_envs)\n",
    "print('Accuracy on the selected {} environments are {}'.format(len(eval_envs), dev_avg_return))\n",
    "print('Show the generated programs:')\n",
    "print(exp.show_samples(dev_samples, envs[0].de_vocab, env_dict=env_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug the beam search by showing programs in the beam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:==================================================\n",
      "INFO:tensorflow:eval, batch 0: 1 envs\n",
      "INFO:tensorflow:5 samples in beam, batch 0.\n",
      "INFO:tensorflow:0.2055580616 sec used in evaluator batch 0.\n",
      "INFO:tensorflow:avg return adjusted from 1.0 to 1.0 based on true n\n",
      "INFO:tensorflow:1 samples in non-empty beam.\n",
      "INFO:tensorflow:true n is 1\n",
      "INFO:tensorflow:1 questions in dev set.\n",
      "INFO:tensorflow:1.0 dev avg return.\n",
      "INFO:tensorflow:dev: avg return: 1.0, avg length: 11.0.\n",
      "Show the 5 programs in beam for environment nt-13901:\n",
      "\n",
      "env nt-13901\n",
      "question: the most points were scored by which player?\n",
      "answer: [u'Karel Hrom\\xe1dka', u'Karel Hrom\\xe1dka']\n",
      "program: ( argmax all_rows r._points-number ) ( hop v10 r.player-string ) <END>\n",
      "prediction: [u'karel hromadka']\n",
      "return: 1.0\n",
      "prob is 0.879124546146\n",
      "\n",
      "env nt-13901\n",
      "question: the most points were scored by which player?\n",
      "answer: [u'Karel Hrom\\xe1dka', u'Karel Hrom\\xe1dka']\n",
      "program: ( argmin all_rows r._points-number ) ( hop v10 r.player-string ) <END>\n",
      "prediction: [u'dawid daniuszewski', u'endre steiner', u'otto zimmermann', u'damian reca', u'giovanni cenni', u'karoly sterk']\n",
      "return: 0.0\n",
      "prob is 0.108504561195\n",
      "\n",
      "env nt-13901\n",
      "question: the most points were scored by which player?\n",
      "answer: [u'Karel Hrom\\xe1dka', u'Karel Hrom\\xe1dka']\n",
      "program: ( maximum all_rows r._points-number ) ( filter_eq all_rows v10 r._points-number ) ( hop v11 r.player-string ) <END>\n",
      "prediction: [u'karel hromadka']\n",
      "return: 1.0\n",
      "prob is 0.00758838433011\n",
      "\n",
      "env nt-13901\n",
      "question: the most points were scored by which player?\n",
      "answer: [u'Karel Hrom\\xe1dka', u'Karel Hrom\\xe1dka']\n",
      "program: ( last all_rows ) ( hop v10 r.player-string ) <END>\n",
      "prediction: [u'etc']\n",
      "return: 0.0\n",
      "prob is 0.00346565319935\n",
      "\n",
      "env nt-13901\n",
      "question: the most points were scored by which player?\n",
      "answer: [u'Karel Hrom\\xe1dka', u'Karel Hrom\\xe1dka']\n",
      "program: ( maximum all_rows r._points-number ) ( filter_not_eq all_rows v10 r._points-number ) ( maximum v11 r._points-number ) <END>\n",
      "prediction: [9.0]\n",
      "return: 0.0\n",
      "prob is 0.0013168551291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_id = 'nt-13901'\n",
    "dev_avg_return, dev_samples, dev_samples_in_beam = exp.beam_search_eval(agent, [env_dict[env_id]])\n",
    "print('Show the {} programs in beam for environment {}:'.format(len(dev_samples_in_beam), env_id))\n",
    "print(exp.show_samples(dev_samples_in_beam, envs[0].de_vocab, env_dict=env_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
